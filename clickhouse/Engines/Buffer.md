# Buffer


缓存数据在RAM(内存)中，定期将刷新到另一个表。在读取操作期间，同时从缓冲和相印表中读取数据。
```
Buffer(database, table, num_layers, min_time, max_time, min_rows, max_rows, min_bytes, max_bytes)
```

引擎参数:
* database, table： 要将数据刷新到的表。您可以使用返回字串的常量表达式，而不是字符串名。
* num_layers： 并行级别。物理上，表将视为互相独立的数量为'num_layers'个的buffer。推荐值为16。
* min_time, max_time, min_rows, max_rows, min_bytes, and max_bytes: 是从缓冲区刷出数据的条件。如果满足所有“最小”条件或至少一个“最大”条件，则将数据从缓冲区刷新并写入目标表。
  * min_time, max_timee： 从第一次写入缓冲区那一刻起的时间条件(以秒为单位)。
  * min_rows, max_rowse：缓冲区中行数的条件。
  * min_bytes, max_bytes：缓冲区中字节数的条件。

在写入操作期间，将数据插入到num_layers数量的随机缓冲区中。或者，如果要插入的数据部分足够大(大于 ‘max_rows’ or ‘max_bytes’)，则直接写入目标表，而略过缓冲区。

刷新目标表的条件是每个缓冲区互相独立计算的。例如，当num_layers = 16且max_bytes = 100000000，则最大RAM消耗为1.6GB。

#### 例子
```
CREATE TABLE merge.hits_buffer AS merge.hits ENGINE = Buffer(merge, hits, 16, 10, 100, 10000, 1000000, 10000000, 100000000)
```
使用缓冲区引擎创建具有与merge.hits相同结构的 merge.hits_buffer表。
写入此表时，数据缓存在RAM中，然后写入merge.hits表。创建了16个缓冲区。

如果已经过去100秒，或者已经写入一百万行，或者已经写入100MB的数据，则刷新它们中的每一个中的数据；
或者如果同时已经过去10秒并且已经写入10，000行和10mb的数据,也刷新它们中的每一个中的数据；
例如，如果只写入了一行，则100秒后，无论发生什么情况，都将刷新该行。但是，如果写入了许多行，数据将更快被刷新。

当服务器停止时，使用DROP TABLE或DETACHTABLE，缓冲区数据也会刷新到目标表。

可以为数据库和表名设置单引号中的空字符串。这表示没有目标表。在这种情况下，当达到数据刷新条件时，只会清除缓冲区。
这对于在内存中保持窗口数据是有用的。

从缓冲区表读取数据时，将同时从缓冲区和目标表(如果有)获取数据。请注意，缓冲区表不支持索引。
换句话说，缓冲区中的数据被完全扫描，这对于大缓冲区来说可能是缓慢的。(对于从属表中的数据，将使用其支持的索引。)

#### 特点
如果缓冲表中的列集与从属表中的列集不匹配，则会插入两个表中存在的列子集。

如果缓冲区表和从属表中的没有任何一列匹配，则会在服务器日志中输入错误消息并清除缓冲区。当缓冲区被刷新时，如果从属表不存在，也会发生同样的情况。

如果需要对从属表和缓冲区表运行ALTER，建议首先删除缓冲区表，对从属表运行ALTER，然后再次创建缓冲区表。

如果服务器异常重新启动，缓冲区中的数据将丢失。

PREWHERE、FINAL和SAMPLE不能正确用于缓冲表。这些条件传递到目标表，但不用于处理缓冲区中的数据。
因此，我们建议在从目标表读取时仅使用缓冲区表进行写入。

向一个缓冲区添加数据时，这个缓冲区被锁定。如果同时从表中执行读取操作，这将导致读取延迟。

插入缓冲表的数据可能以不同的顺序和不同的块结束在从属表中。因此，很难使用缓冲区表正确写入CollapsingMergeTree 。为了避免出现问题，可以将“num _layers”设置为1。

如果目标表是复制表(replicated)，则在写入缓冲表时，复制表的某些预期特性将丢失。
对行顺序和数据部分大小的随机更改会导致消除重复数据停止工作，这意味着不可能对复制的表进行可靠的'exactly once' 写入。

#### 建议
由于这些缺点，**我们只能建议在极少数情况下使用缓冲表**。
当在一个时间单位内从大量服务器接收到过多的INSERTs，并且在插入之前无法缓冲数据时，意味着无法足够快地运行INSERTs操作，则考虑使用缓冲表。

请注意，即使对于缓冲表，一次插入一行数据也是没有意义的。这将仅产生每秒几千行的速度，而插入较大的数据块每秒可产生超过一百万行(请参见“性能”一节)。
